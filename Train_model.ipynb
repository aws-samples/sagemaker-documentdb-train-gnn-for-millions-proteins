{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "561371c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab1eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "secrets = json.load(open('DocumentDB_secrets.json', 'r')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "612a2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TLS enabled\n",
    "uri = 'mongodb://{}:{}@{}:27017/?tls=true&tlsCAFile=rds-combined-ca-bundle.pem&replicaSet=rs0&readPreference=secondaryPreferred&retryWrites=false'\\\n",
    "    .format(secrets['db_username'], secrets['db_password'], secrets['host'])\n",
    "\n",
    "client = MongoClient(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd91efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client['proteins']\n",
    "collection = db['proteins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebeae034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70788812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37458653",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d34ec86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _connect_to_db():\n",
    "    uri = 'mongodb://{}:{}@{}:27017/?tls=true&tlsCAFile=rds-combined-ca-bundle.pem&replicaSet=rs0&readPreference=secondaryPreferred&retryWrites=false'\\\n",
    "        .format(secrets['db_username'], secrets['db_password'], secrets['host'])\n",
    "\n",
    "    client = MongoClient(uri)\n",
    "    db = client['proteins']\n",
    "    collection = db['proteins']\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "453ec1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from Bio.PDB.Polypeptide import d1_to_index, three_to_one\n",
    "\n",
    "# d1_to_index['X'] = len(d1_to_index) # encode uncommon residue as 20\n",
    "d1_to_index['X'] = 20\n",
    "\n",
    "def _convert_to_graph(protein):\n",
    "    '''\n",
    "    Convert a protein (dict) to a dgl graph\n",
    "    '''\n",
    "    coords = torch.tensor(protein['coords'])\n",
    "    X_ca = coords[:, 1]\n",
    "    # construct knn graph from C-alpha coordinates\n",
    "    g = dgl.knn_graph(X_ca, k=2)        \n",
    "    seq = protein['seq']\n",
    "    node_features = torch.tensor([d1_to_index[residue] for residue in seq])\n",
    "    node_features = F.one_hot(node_features, num_classes=len(d1_to_index)).to(dtype=torch.float)\n",
    "\n",
    "    # add node features\n",
    "    g.ndata[\"h\"] = node_features\n",
    "    return g    \n",
    "\n",
    "class ProteinDataset(data.Dataset):\n",
    "    \"\"\"Map-style Dataset\"\"\"\n",
    "    def __init__(self, collection, pipeline):\n",
    "        \"\"\"\n",
    "        \n",
    "        Args:\n",
    "            - collection: pymongo.collection.Collection object\n",
    "            - pipeline: a DocumentDB aggregation pipeline\n",
    "            - tokenizer:\n",
    "        \"\"\"\n",
    "        self.collection = collection\n",
    "        # pre-fetch the metadata and labels from DocumentDB\n",
    "        self.docs = [doc for doc in self.collection.aggregate(pipeline)]\n",
    "        self.labels = [doc[\"y\"] for doc in self.docs]\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        id_ = self.docs[idx]['id']\n",
    "#         collection = _connect_to_db()\n",
    "        protein = self.collection.find_one(\n",
    "            {'id': id_}, \n",
    "            projection={\"_id\": False, \"coords\": True, \"seq\": True}\n",
    "        )\n",
    "        return _convert_to_graph(protein), self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.docs)\n",
    "\n",
    "class IProteinDataset(data.IterableDataset):\n",
    "    \"\"\"\"\"\"\n",
    "    def __init__(self, collection, pipeline):\n",
    "        self.collection = collection\n",
    "        # pre-fetch the metadata and labels from DocumentDB\n",
    "        self.docs = [doc for doc in self.collection.aggregate(pipeline)]\n",
    "        self.labels = {doc['_id']: doc[\"y\"] for doc in self.docs}\n",
    "#         self.batch_size = batch_size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        if worker_info is None:  # single-process data loading, return the full iterator\n",
    "            protein_ids = [doc['_id'] for doc in self.docs]\n",
    "            \n",
    "        else:  # in a worker process\n",
    "            # split workload\n",
    "            start = 0\n",
    "            end = len(self.docs)\n",
    "            per_worker = int(math.ceil((end - start) / float(worker_info.num_workers)))\n",
    "            worker_id = worker_info.id\n",
    "            iter_start = start + worker_id * per_worker\n",
    "            iter_end = min(iter_start + per_worker, end)\n",
    "            \n",
    "            protein_ids = [doc['_id'] for doc in self.docs[iter_start:iter_end]]\n",
    "        \n",
    "        # retrieve a list of proteins by _id from DocDB\n",
    "        cur = self.collection.find(\n",
    "            {'_id': {'$in': protein_ids}}, \n",
    "            projection={\"coords\": True, \"seq\": True}\n",
    "        )\n",
    "        return ((_convert_to_graph(protein), self.labels[protein['_id']]) \\\n",
    "                for protein in cur)\n",
    "        \n",
    "    def shuffle(self):\n",
    "        random.shuffle(self.docs)\n",
    "        \n",
    "def collate(samples):\n",
    "#     graphs = list(zip(*samples))[0]\n",
    "#     targets = list(zip(*samples))[1]\n",
    "    graphs, targets = map(list, zip(*samples))\n",
    "    bg = dgl.batch(graphs)\n",
    "    return bg, torch.tensor(targets).unsqueeze(1).to(torch.float32)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d80df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(uri, connect=False)\n",
    "db = client['proteins']\n",
    "collection = db['proteins']\n",
    "\n",
    "match = {\"is_AF\": {\"$exists\": True}}\n",
    "project = {\"y\": \"$is_AF\"}\n",
    "\n",
    "pipeline = [\n",
    "    {\"$match\": match},\n",
    "    {\"$project\": project},\n",
    "]\n",
    "\n",
    "\n",
    "ds = IProteinDataset(collection, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eefdff8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3151"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [doc for doc in collection.aggregate(pipeline)]\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b1ccc998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ObjectId('611fed5aa9e1be4d05332068'),\n",
       " ObjectId('611fed5aa9e1be4d05332069'),\n",
       " ObjectId('611fed5aa9e1be4d0533206a'),\n",
       " ObjectId('611fed5ba9e1be4d0533206b')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_ids = [doc['_id'] for doc in docs[:4]]\n",
    "protein_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "30fb2442",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = collection.find(\n",
    "    {'_id': {'$in': protein_ids}}, \n",
    "    projection={\"coords\": True, \"seq\": True, \"is_AF\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "495c44eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pymongo.cursor.Cursor"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2c9f2383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['_id', 'seq', 'coords', 'is_AF'])\n",
      "dict_keys(['_id', 'seq', 'coords', 'is_AF'])\n",
      "dict_keys(['_id', 'seq', 'coords', 'is_AF'])\n",
      "dict_keys(['_id', 'seq', 'coords', 'is_AF'])\n"
     ]
    }
   ],
   "source": [
    "for protein in proteins:\n",
    "    print(protein.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7f23b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {protein['_id']: protein['is_AF'] for protein in proteins}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1782bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df9feac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=1440, num_edges=2880,\n",
      "      ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
      "      edata_schemes={}) tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "for bg, labels in data.DataLoader(ds, num_workers=0, \n",
    "                             batch_size=4, collate_fn=collate):\n",
    "    print(bg, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dce727a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/pymongo/topology.py:165: UserWarning: MongoClient opened before fork. Create MongoClient only after forking. See PyMongo's documentation for details: https://pymongo.readthedocs.io/en/stable/faq.html#is-pymongo-fork-safe\n",
      "  \"MongoClient opened before fork. Create MongoClient only \"\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/pymongo/topology.py:165: UserWarning: MongoClient opened before fork. Create MongoClient only after forking. See PyMongo's documentation for details: https://pymongo.readthedocs.io/en/stable/faq.html#is-pymongo-fork-safe\n",
      "  \"MongoClient opened before fork. Create MongoClient only \"\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fc97ca62860>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()Exception ignored in: \n",
      "<bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fc97ca62860>>  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "AssertionError    : w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)can only join a child process\n",
      "\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=1440, num_edges=2880,\n",
      "      ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
      "      edata_schemes={}) tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "for bg, labels in data.DataLoader(ds, num_workers=2, \n",
    "                             batch_size=4, collate_fn=collate):\n",
    "    print(bg, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf7c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.find(\n",
    "                {'id': {'$in': protein_ids}}, \n",
    "                projection={\"_id\": False, \"coords\": True, \"seq\": True}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995656a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f8d95d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'AF-Q57935', 'y': 1}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = dataset.docs[0]\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "34321724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 ms ± 762 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# id_ = doc['id']\n",
    "collection = _connect_to_db()\n",
    "protein = collection.find_one(\n",
    "    {'id': id_}, \n",
    "    projection={\"_id\": False, \"coords\": True, \"seq\": True}\n",
    ")\n",
    "# 179 ms ± 8.28 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "307d0821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173 ms ± 2.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# id_ = doc['id']\n",
    "collection = _connect_to_db()\n",
    "protein = collection.find_one(\n",
    "    {'id': id_}, \n",
    "    projection={\"_id\": False, \"seq\": True}\n",
    ")\n",
    "# 179 ms ± 8.28 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "708cb0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = doc['id']\n",
    "collection = _connect_to_db()\n",
    "protein = collection.find_one(\n",
    "    {'id': id_}, \n",
    "    projection={\"_id\": False, \"coords\": True, \"seq\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f52917d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.18 ms ± 75.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "collection = _connect_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41324273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.13 ms ± 26.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "protein = collection.find_one(\n",
    "    {'id': id_}, \n",
    "    projection={\"_id\": False, \"coords\": True, \"seq\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0cc704c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6 ms ± 10.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "coords = torch.tensor(protein['coords'])\n",
    "X_ca = coords[:, 1]\n",
    "# construct knn graph from C-alpha coordinates\n",
    "g = dgl.knn_graph(X_ca, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c458ef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = torch.tensor(protein['coords'])\n",
    "X_ca = coords[:, 1]\n",
    "# construct knn graph from C-alpha coordinates\n",
    "g = dgl.knn_graph(X_ca, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ecea41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 µs ± 205 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "seq = protein['seq']\n",
    "node_features = torch.tensor([d1_to_index[residue] for residue in seq])\n",
    "node_features = F.one_hot(node_features, num_classes=len(d1_to_index)).to(dtype=torch.float)\n",
    "\n",
    "# add node features\n",
    "g.ndata[\"h\"] = node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cfa9b7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 ms ± 4.08 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829271d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce97de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e266575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = {\"is_AF\": {\"$exists\": True}}\n",
    "project = {\"y\": \"$is_AF\", \"_id\": False, 'id': True}\n",
    "\n",
    "pipeline = [\n",
    "    {\"$match\": match},\n",
    "    {\"$project\": project},\n",
    "]\n",
    "\n",
    "# docs = [doc for doc in collection.aggregate(pipeline)]\n",
    "# docs[0]\n",
    "dataset = ProteinDataset(collection, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c472f3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Graph(num_nodes=380, num_edges=760,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g, label = dataset[0]\n",
    "g, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b26d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac70a2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([1378, 1773]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69e2fb68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7ccb311",
   "metadata": {},
   "source": [
    "## GNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c85155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "num_examples = len(dataset)\n",
    "num_train = int(num_examples * 0.8)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(torch.arange(num_train))\n",
    "test_sampler = SubsetRandomSampler(torch.arange(num_train, num_examples))\n",
    "\n",
    "# train_dataloader = GraphDataLoader(\n",
    "#     dataset, sampler=train_sampler, batch_size=32, drop_last=False,\n",
    "#     num_workers=16\n",
    "# )\n",
    "# test_dataloader = GraphDataLoader(\n",
    "#     dataset, sampler=test_sampler, batch_size=32, drop_last=False)\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    dataset, sampler=train_sampler, batch_size=32, \n",
    "    collate_fn=collate,\n",
    "    num_workers=32\n",
    ")\n",
    "\n",
    "test_dataloader = data.DataLoader(\n",
    "    dataset, sampler=test_sampler, batch_size=32, \n",
    "    collate_fn=collate,\n",
    "#     num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a8f02f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 20)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5b13a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Graph(num_nodes=7887, num_edges=15774,\n",
      "      ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
      "      edata_schemes={}), tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]))\n"
     ]
    }
   ],
   "source": [
    "it = iter(train_dataloader)\n",
    "batch = next(it)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abbf3123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.5 s ± 2.19 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "it = iter(train_dataloader)\n",
    "batch = next(it)\n",
    "# bs=workers=32\n",
    "# 10.5 s ± 2.19 s per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6674da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data.DataLoader(\n",
    "    dataset, sampler=train_sampler, batch_size=1, \n",
    "    collate_fn=collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f57b0991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 ms ± 14.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "it = iter(train_dataloader)\n",
    "batch = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a570eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data.DataLoader(\n",
    "    dataset, sampler=train_sampler, batch_size=32, \n",
    "    collate_fn=collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "03f8e108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.08 s ± 78.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "it = iter(train_dataloader)\n",
    "batch = next(it)\n",
    "# bs=32, workers=0\n",
    "# 5.99 s ± 76 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49da3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data.DataLoader(\n",
    "    dataset, sampler=train_sampler, batch_size=32, \n",
    "    collate_fn=collate,\n",
    "    num_workers=32,\n",
    "    persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43139299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.2 s ± 3.72 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "it = iter(train_dataloader)\n",
    "batch = next(it)\n",
    "# bs=workers=32 persistent_workers=True\n",
    "# 25.2 s ± 3.72 s per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127db16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2318348f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Graph(num_nodes=1155, num_edges=2310,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=115, num_edges=230,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=237, num_edges=474,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=203, num_edges=406,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=342, num_edges=684,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=317, num_edges=634,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=214, num_edges=428,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=39, num_edges=78,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=222, num_edges=444,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=415, num_edges=830,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=206, num_edges=412,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=297, num_edges=594,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=82, num_edges=164,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=117, num_edges=234,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=197, num_edges=394,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=372, num_edges=744,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=79, num_edges=158,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=358, num_edges=716,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=519, num_edges=1038,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=155, num_edges=310,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=208, num_edges=416,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=152, num_edges=304,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=153, num_edges=306,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=202, num_edges=404,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=240, num_edges=480,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=230, num_edges=460,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=86, num_edges=172,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=129, num_edges=258,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=207, num_edges=414,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=268, num_edges=536,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=183, num_edges=366,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=188, num_edges=376,\n",
       "       ndata_schemes={'h': Scheme(shape=(21,), dtype=torch.float32)}\n",
       "       edata_schemes={})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgl.unbatch(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a09f6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        return dgl.mean_nodes(g, 'h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92dd2daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with given dimensions\n",
    "dim_nfeats = len(d1_to_index)\n",
    "n_classes = 1\n",
    "\n",
    "model = GCN(dim_nfeats, 16, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b78cbf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c43c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94a29348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0df63558",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data.DataLoader(\n",
    "    dataset, sampler=train_sampler, batch_size=32, \n",
    "    collate_fn=collate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf3141be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 1\n",
      "Time elapsed: 0:15:49.611212\n"
     ]
    }
   ],
   "source": [
    "t0 = datetime.now()\n",
    "model.train()\n",
    "for epoch in range(2):\n",
    "    print('epoch:', epoch)\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        \n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        pred = model(batched_graph, batched_graph.ndata['h'])\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('Time elapsed:', datetime.now() - t0)\n",
    "# Time elapsed: 0:00:59.909561: bs=workers=32\n",
    "# Time elapsed: 0:15:49.611212 bs=32 workers=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "744fc149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 31.671949286846274\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_tests = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batched_graph, labels in test_dataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        pred = model(batched_graph, batched_graph.ndata['h'].float())\n",
    "        num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "        num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy:', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e9370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d0f42f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "38e59f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.binary_cross_entropy_with_logits(pred, labels.to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "07a4f9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, torch.float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.dtype, pred.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "36e1b884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape, pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "64b5b581",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "multi-target not supported at /opt/conda/conda-bld/pytorch_1607370116979/work/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-ec1fb27f7f39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2262\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   2263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2264\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2265\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: multi-target not supported at /opt/conda/conda-bld/pytorch_1607370116979/work/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15"
     ]
    }
   ],
   "source": [
    "loss = F.bincross_entropy(pred, labels.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7bec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
