{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e2f091",
   "metadata": {},
   "source": [
    "# Training Amazon SageMaker models by using the Deep Graph Library with PyTorch backend\n",
    "\n",
    "https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/dgl_gcn/pytorch_gcn.ipynb\n",
    "\n",
    "## Setup\n",
    "\n",
    "Define a few variables that are needed later in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47aa89aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "# Setup session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here.\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# IAM execution role that gives Amazon SageMaker access to resources in your AWS account.\n",
    "# You can use the Amazon SageMaker Python SDK to get the role from the notebook environment.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c191e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::479389006481:role/DocDB-SM-SageMakerRoleName'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9235ba7",
   "metadata": {},
   "source": [
    "## The training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0e1bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat src/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f9e780",
   "metadata": {},
   "source": [
    "## SageMaker's estimator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f58bf48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp rds-combined-ca-bundle.pem src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49d4d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "# Get DocumentDB credentials stored in Secrets Manager\n",
    "def get_secret(stack_name):\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=session.region_name\n",
    "    )\n",
    "    \n",
    "    secret_name = f'{stack_name}-DocDBSecret'\n",
    "    get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9314e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets = get_secret('DocDB-SM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2574133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4c6a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "CODE_PATH = \"main.py\"\n",
    "account = sess.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "params = {\n",
    "    'patience': 5, \n",
    "    'n-epochs': 10,\n",
    "    'batch-size': 64,\n",
    "    'db-host': secrets['host'],\n",
    "    'db-username': secrets['username'], \n",
    "    'db-password': secrets['password'], \n",
    "    'db-port': secrets['port'],\n",
    "    \n",
    "}\n",
    "task_tags = [{\"Key\": \"ML Task\", \"Value\": \"DGL\"}]\n",
    "estimator = PyTorch(\n",
    "    entry_point=CODE_PATH,\n",
    "    source_dir='src',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "#     instance_type=\"ml.p3.2xlarge\",\n",
    "    instance_type='ml.c4.2xlarge',\n",
    "#     instance_type='local',\n",
    "    framework_version=\"1.7.1\",\n",
    "    py_version=\"py3\",\n",
    "    hyperparameters=params,\n",
    "    sagemaker_session=sess,\n",
    "#     subnets=['subnet-059a93a71fc411609'],\n",
    "#     subnets=['subnet-0452015a17db921f5'], # DocDB-SM-PrivateOne\n",
    "    subnets=['subnet-08bf5904187d12262'], # NAT-subnet\n",
    "    security_group_ids=['sg-0b571292a85eaad77'],    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c135eba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Subnets': ['subnet-08bf5904187d12262'],\n",
       " 'SecurityGroupIds': ['sg-0b571292a85eaad77']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.get_vpc_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a37586",
   "metadata": {},
   "source": [
    "## Running the Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56af351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-25 23:37:05 Starting - Starting the training job...\n",
      "2021-08-25 23:37:28 Starting - Launching requested ML instancesProfilerReport-1629934624: InProgress\n",
      "...\n",
      "2021-08-25 23:37:56 Starting - Preparing the instances for training.........\n",
      "2021-08-25 23:39:35 Downloading - Downloading input data\n",
      "2021-08-25 23:39:35 Training - Downloading the training image...\n",
      "2021-08-25 23:39:51 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-08-25 23:39:52,395 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-08-25 23:39:52,397 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-08-25 23:39:52,408 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-08-25 23:39:52,421 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-08-25 23:39:52,797 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting pymongo==3.12.0\n",
      "  Downloading pymongo-3.12.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (523 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pymongo\u001b[0m\n",
      "\u001b[34mSuccessfully installed pymongo-3.12.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\n",
      "\u001b[34m2021-08-25 23:39:56,020 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-08-25 23:39:56,033 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-08-25 23:39:56,046 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-08-25 23:39:56,057 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 64,\n",
      "        \"db-username\": \"janssen\",\n",
      "        \"db-host\": \"docdb-sm-documentdb.cluster-crip7tlhkoam.us-east-2.docdb.amazonaws.com\",\n",
      "        \"db-port\": 27017,\n",
      "        \"n-epochs\": 10,\n",
      "        \"patience\": 5,\n",
      "        \"db-password\": \"Janssen123!\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2021-08-25-23-37-04-805\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-479389006481/pytorch-training-2021-08-25-23-37-04-805/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"main\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"main.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":64,\"db-host\":\"docdb-sm-documentdb.cluster-crip7tlhkoam.us-east-2.docdb.amazonaws.com\",\"db-password\":\"Janssen123!\",\"db-port\":27017,\"db-username\":\"janssen\",\"n-epochs\":10,\"patience\":5}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=main.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=main\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-479389006481/pytorch-training-2021-08-25-23-37-04-805/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"db-host\":\"docdb-sm-documentdb.cluster-crip7tlhkoam.us-east-2.docdb.amazonaws.com\",\"db-password\":\"Janssen123!\",\"db-port\":27017,\"db-username\":\"janssen\",\"n-epochs\":10,\"patience\":5},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-08-25-23-37-04-805\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-479389006481/pytorch-training-2021-08-25-23-37-04-805/source/sourcedir.tar.gz\",\"module_name\":\"main\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"main.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"64\",\"--db-host\",\"docdb-sm-documentdb.cluster-crip7tlhkoam.us-east-2.docdb.amazonaws.com\",\"--db-password\",\"Janssen123!\",\"--db-port\",\"27017\",\"--db-username\",\"janssen\",\"--n-epochs\",\"10\",\"--patience\",\"5\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_DB-USERNAME=janssen\u001b[0m\n",
      "\u001b[34mSM_HP_DB-HOST=docdb-sm-documentdb.cluster-crip7tlhkoam.us-east-2.docdb.amazonaws.com\u001b[0m\n",
      "\u001b[34mSM_HP_DB-PORT=27017\u001b[0m\n",
      "\u001b[34mSM_HP_N-EPOCHS=10\u001b[0m\n",
      "\u001b[34mSM_HP_PATIENCE=5\u001b[0m\n",
      "\u001b[34mSM_HP_DB-PASSWORD=Janssen123!\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 main.py --batch-size 64 --db-host docdb-sm-documentdb.cluster-crip7tlhkoam.us-east-2.docdb.amazonaws.com --db-password Janssen123! --db-port 27017 --db-username janssen --n-epochs 10 --patience 5\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mos.getcwd(): /opt/ml/code\u001b[0m\n",
      "\u001b[34mscript dir: /opt/ml/code\u001b[0m\n",
      "\u001b[34min script dir: ['requirements.txt', '.ipynb_checkpoints', 'rds-combined-ca-bundle.pem', 'main.py']\u001b[0m\n",
      "\u001b[34m{'batch_size': 64, 'lr': 0.001, 'n_epochs': 10, 'db_host': 'docdb-sm-documentdb.cluster-crip7tlhkoam.us-east-2.docdb.amazonaws.com', 'db_port': '27017', 'db_username': 'janssen', 'db_password': 'Janssen123!', 'patience': 5}\u001b[0m\n",
      "\u001b[34m[2021-08-25 23:40:01.279 algo-1:32 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-08-25 23:40:01.420 algo-1:32 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-08-25 23:40:01.420 algo-1:32 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-08-25 23:40:01.420 algo-1:32 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-08-25 23:40:01.421 algo-1:32 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-08-25 23:40:01.421 algo-1:32 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-08-25 23:40:04.469 algo-1:32 INFO hook.py:591] name:conv1.weight count_params:336\u001b[0m\n",
      "\u001b[34m[2021-08-25 23:40:04.469 algo-1:32 INFO hook.py:591] name:conv1.bias count_params:16\u001b[0m\n",
      "\u001b[34m[2021-08-25 23:40:04.469 algo-1:32 INFO hook.py:591] name:conv2.weight count_params:16\u001b[0m\n",
      "\u001b[34m[2021-08-25 23:40:04.469 algo-1:32 INFO hook.py:591] name:conv2.bias count_params:1\u001b[0m\n",
      "\u001b[34m[2021-08-25 23:40:04.470 algo-1:32 INFO hook.py:593] Total Trainable Params: 369\u001b[0m\n",
      "\u001b[34m[2021-08-25 23:40:04.470 algo-1:32 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-08-25 23:40:04.474 algo-1:32 INFO hook.py:488] Hook is writing from the hook with pid: 32\n",
      "\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 1, loss 0.6315\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 2, loss 0.6107\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 3, loss 0.6059\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 4, loss 0.6038\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 5, loss 0.6451\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 6, loss 0.7997\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 7, loss 0.8029\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 8, loss 0.8018\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 9, loss 0.6346\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 10, loss 0.5956\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 11, loss 0.5963\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 12, loss 0.5946\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 13, loss 0.6661\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 14, loss 0.8036\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 15, loss 0.8064\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 16, loss 0.8063\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 17, loss 0.6033\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 18, loss 0.5931\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 19, loss 0.5925\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 20, loss 0.5912\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 21, loss 0.6815\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 22, loss 0.8066\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 23, loss 0.8087\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 24, loss 0.8095\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 25, loss 0.6225\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 26, loss 0.5902\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 27, loss 0.5911\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 28, loss 0.5901\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 29, loss 0.6960\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 30, loss 0.8077\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 31, loss 0.8081\u001b[0m\n",
      "\u001b[34mepoch 1/10, batch 32, loss 0.8108\u001b[0m\n",
      "\u001b[34mepoch 1/10, training roc-auc 0.3627\u001b[0m\n",
      "\u001b[34mepoch 1/10, validation roc-auc 0.5433, best validation roc-auc 0.5433\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 1, loss 0.6244\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 2, loss 0.5907\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 3, loss 0.5895\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 4, loss 0.5900\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 5, loss 0.6871\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 6, loss 0.8073\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 7, loss 0.8090\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 8, loss 0.8089\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 9, loss 0.6121\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 10, loss 0.5900\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 11, loss 0.5912\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 12, loss 0.5895\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 13, loss 0.6664\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 14, loss 0.8081\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 15, loss 0.8094\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 16, loss 0.8101\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 17, loss 0.6082\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 18, loss 0.5893\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 19, loss 0.5886\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 20, loss 0.5884\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 21, loss 0.6504\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 22, loss 0.8096\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 23, loss 0.8108\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 24, loss 0.8110\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 25, loss 0.6206\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 26, loss 0.5881\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 27, loss 0.5892\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 28, loss 0.5874\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 29, loss 0.6754\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 30, loss 0.8096\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 31, loss 0.8127\u001b[0m\n",
      "\u001b[34mepoch 2/10, batch 32, loss 0.8133\u001b[0m\n",
      "\u001b[34mepoch 2/10, training roc-auc 0.4822\u001b[0m\n",
      "\u001b[34mepoch 2/10, validation roc-auc 0.5921, best validation roc-auc 0.5921\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 1, loss 0.6285\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 2, loss 0.5875\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 3, loss 0.5872\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 4, loss 0.5868\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 5, loss 0.6636\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 6, loss 0.8077\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 7, loss 0.8116\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 8, loss 0.8124\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 9, loss 0.6105\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 10, loss 0.5877\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 11, loss 0.5872\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 12, loss 0.5862\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 13, loss 0.6750\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 14, loss 0.8119\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 15, loss 0.8125\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 16, loss 0.8119\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 17, loss 0.6130\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 18, loss 0.5860\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 19, loss 0.5862\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 20, loss 0.5860\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 21, loss 0.6701\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 22, loss 0.8113\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 23, loss 0.8137\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 24, loss 0.8145\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 25, loss 0.6040\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 26, loss 0.5862\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 27, loss 0.5870\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 28, loss 0.5852\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 29, loss 0.6673\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 30, loss 0.8133\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 31, loss 0.8140\u001b[0m\n",
      "\u001b[34mepoch 3/10, batch 32, loss 0.8149\u001b[0m\n",
      "\u001b[34mepoch 3/10, training roc-auc 0.5235\u001b[0m\n",
      "\u001b[34mepoch 3/10, validation roc-auc 0.6320, best validation roc-auc 0.6320\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 1, loss 0.6047\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 2, loss 0.5844\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 3, loss 0.5856\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 4, loss 0.5849\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 5, loss 0.6742\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 6, loss 0.8118\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 7, loss 0.8154\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 8, loss 0.8159\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 9, loss 0.6156\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 10, loss 0.5847\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 11, loss 0.5847\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 12, loss 0.5827\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 13, loss 0.6592\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 14, loss 0.8134\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 15, loss 0.8157\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 16, loss 0.8159\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 17, loss 0.6109\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 18, loss 0.5840\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 19, loss 0.5829\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 20, loss 0.5824\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 21, loss 0.6804\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 22, loss 0.8151\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 23, loss 0.8158\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 24, loss 0.8153\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 25, loss 0.6178\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 26, loss 0.5834\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 27, loss 0.5837\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 28, loss 0.5833\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 29, loss 0.6584\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 30, loss 0.8136\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 31, loss 0.8147\u001b[0m\n",
      "\u001b[34mepoch 4/10, batch 32, loss 0.8169\u001b[0m\n",
      "\u001b[34mepoch 4/10, training roc-auc 0.5594\u001b[0m\n",
      "\u001b[34mepoch 4/10, validation roc-auc 0.6637, best validation roc-auc 0.6637\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 1, loss 0.6134\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 2, loss 0.5828\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 3, loss 0.5823\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 4, loss 0.5816\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 5, loss 0.6795\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 6, loss 0.8157\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 7, loss 0.8169\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 8, loss 0.8175\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 9, loss 0.6172\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 10, loss 0.5827\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 11, loss 0.5834\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 12, loss 0.5804\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 13, loss 0.6693\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 14, loss 0.8152\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 15, loss 0.8167\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 16, loss 0.8165\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 17, loss 0.6003\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 18, loss 0.5823\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 19, loss 0.5818\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 20, loss 0.5821\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 21, loss 0.6618\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 22, loss 0.8146\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 23, loss 0.8163\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 24, loss 0.8176\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 25, loss 0.6114\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 26, loss 0.5805\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 27, loss 0.5816\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 28, loss 0.5809\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 29, loss 0.6591\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 30, loss 0.8141\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 31, loss 0.8181\u001b[0m\n",
      "\u001b[34mepoch 5/10, batch 32, loss 0.8190\u001b[0m\n",
      "\u001b[34mepoch 5/10, training roc-auc 0.5963\u001b[0m\n",
      "\u001b[34mepoch 5/10, validation roc-auc 0.6888, best validation roc-auc 0.6888\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 1, loss 0.6138\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 2, loss 0.5810\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 3, loss 0.5807\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 4, loss 0.5789\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 5, loss 0.6569\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 6, loss 0.8164\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 7, loss 0.8181\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 8, loss 0.8190\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 9, loss 0.6149\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 10, loss 0.5800\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 11, loss 0.5788\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 12, loss 0.5799\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 13, loss 0.6655\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 14, loss 0.8165\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 15, loss 0.8197\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 16, loss 0.8200\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 17, loss 0.5933\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 18, loss 0.5788\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 19, loss 0.5797\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 20, loss 0.5785\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 21, loss 0.6807\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 22, loss 0.8168\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 23, loss 0.8192\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 24, loss 0.8199\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 25, loss 0.6130\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 26, loss 0.5788\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 27, loss 0.5802\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 28, loss 0.5773\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 29, loss 0.6642\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 30, loss 0.8188\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 31, loss 0.8200\u001b[0m\n",
      "\u001b[34mepoch 6/10, batch 32, loss 0.8211\u001b[0m\n",
      "\u001b[34mepoch 6/10, training roc-auc 0.6222\u001b[0m\n",
      "\u001b[34mepoch 6/10, validation roc-auc 0.7100, best validation roc-auc 0.7100\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 1, loss 0.6005\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 2, loss 0.5779\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 3, loss 0.5793\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 4, loss 0.5778\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 5, loss 0.6644\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 6, loss 0.8209\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 7, loss 0.8195\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 8, loss 0.8206\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 9, loss 0.6212\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 10, loss 0.5779\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 11, loss 0.5773\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 12, loss 0.5752\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 13, loss 0.6693\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 14, loss 0.8182\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 15, loss 0.8202\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 16, loss 0.8222\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 17, loss 0.6137\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 18, loss 0.5783\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 19, loss 0.5775\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 20, loss 0.5764\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 21, loss 0.6771\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 22, loss 0.8193\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 23, loss 0.8209\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 24, loss 0.8208\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 25, loss 0.5922\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 26, loss 0.5768\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 27, loss 0.5776\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 28, loss 0.5778\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 29, loss 0.6533\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 30, loss 0.8151\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 31, loss 0.8220\u001b[0m\n",
      "\u001b[34mepoch 7/10, batch 32, loss 0.8223\u001b[0m\n",
      "\u001b[34mepoch 7/10, training roc-auc 0.6508\u001b[0m\n",
      "\u001b[34mepoch 7/10, validation roc-auc 0.7248, best validation roc-auc 0.7248\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 1, loss 0.6012\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 2, loss 0.5768\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 3, loss 0.5777\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 4, loss 0.5762\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 5, loss 0.6779\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 6, loss 0.8189\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 7, loss 0.8221\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 8, loss 0.8217\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 9, loss 0.6021\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 10, loss 0.5761\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 11, loss 0.5746\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 12, loss 0.5736\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 13, loss 0.6564\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 14, loss 0.8191\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 15, loss 0.8207\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 16, loss 0.8227\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 17, loss 0.6060\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 18, loss 0.5771\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 19, loss 0.5768\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 20, loss 0.5748\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 21, loss 0.6433\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 22, loss 0.8209\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 23, loss 0.8228\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 24, loss 0.8236\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 25, loss 0.6138\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 26, loss 0.5731\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 27, loss 0.5749\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 28, loss 0.5744\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 29, loss 0.6861\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 30, loss 0.8211\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 31, loss 0.8236\u001b[0m\n",
      "\u001b[34mepoch 8/10, batch 32, loss 0.8251\u001b[0m\n",
      "\u001b[34mepoch 8/10, training roc-auc 0.6669\u001b[0m\n",
      "\u001b[34mepoch 8/10, validation roc-auc 0.7362, best validation roc-auc 0.7362\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 1, loss 0.6051\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 2, loss 0.5742\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 3, loss 0.5747\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 4, loss 0.5731\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 5, loss 0.6513\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 6, loss 0.8215\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 7, loss 0.8245\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 8, loss 0.8237\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 9, loss 0.6024\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 10, loss 0.5752\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 11, loss 0.5742\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 12, loss 0.5730\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 13, loss 0.6579\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 14, loss 0.8198\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 15, loss 0.8245\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 16, loss 0.8236\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 17, loss 0.5952\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 18, loss 0.5728\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 19, loss 0.5741\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 20, loss 0.5726\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 21, loss 0.6717\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 22, loss 0.8232\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 23, loss 0.8240\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 24, loss 0.8269\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 25, loss 0.6137\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 26, loss 0.5726\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 27, loss 0.5727\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 28, loss 0.5717\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 29, loss 0.6800\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 30, loss 0.8218\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 31, loss 0.8224\u001b[0m\n",
      "\u001b[34mepoch 9/10, batch 32, loss 0.8257\u001b[0m\n",
      "\u001b[34mepoch 9/10, training roc-auc 0.6846\u001b[0m\n",
      "\u001b[34mepoch 9/10, validation roc-auc 0.7464, best validation roc-auc 0.7464\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 1, loss 0.5862\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 2, loss 0.5727\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 3, loss 0.5729\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 4, loss 0.5726\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 5, loss 0.6628\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 6, loss 0.8238\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 7, loss 0.8247\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 8, loss 0.8257\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 9, loss 0.6061\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 10, loss 0.5720\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 11, loss 0.5712\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 12, loss 0.5708\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 13, loss 0.6915\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 14, loss 0.8209\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 15, loss 0.8252\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 16, loss 0.8260\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 17, loss 0.6259\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 18, loss 0.5717\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 19, loss 0.5740\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 20, loss 0.5711\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 21, loss 0.6412\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 22, loss 0.8218\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 23, loss 0.8243\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 24, loss 0.8248\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 25, loss 0.5925\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 26, loss 0.5731\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 27, loss 0.5725\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 28, loss 0.5702\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 29, loss 0.6622\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 30, loss 0.8224\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 31, loss 0.8241\u001b[0m\n",
      "\u001b[34mepoch 10/10, batch 32, loss 0.8266\u001b[0m\n",
      "\u001b[34mepoch 10/10, training roc-auc 0.7003\u001b[0m\n",
      "\u001b[34mepoch 10/10, validation roc-auc 0.7539, best validation roc-auc 0.7539\u001b[0m\n",
      "\u001b[34mBest validation score 0.7539\u001b[0m\n",
      "\u001b[34mTest score 0.6985\u001b[0m\n",
      "\u001b[34mUsing backend: pytorch\n",
      "\u001b[0m\n",
      "\u001b[34m2021-08-25 23:41:03,698 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-08-25 23:41:29 Uploading - Uploading generated training model\n",
      "2021-08-25 23:41:29 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec62edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
