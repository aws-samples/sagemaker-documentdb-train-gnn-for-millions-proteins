{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7d560b4",
   "metadata": {},
   "source": [
    "# Training Amazon SageMaker models by using the Deep Graph Library with PyTorch backend\n",
    "\n",
    "https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/dgl_gcn/pytorch_gcn.ipynb\n",
    "\n",
    "## Setup\n",
    "\n",
    "Define a few variables that are needed later in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed3af040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "# Setup session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here.\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# IAM execution role that gives Amazon SageMaker access to resources in your AWS account.\n",
    "# You can use the Amazon SageMaker Python SDK to get the role from the notebook environment.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "964af95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_name = 'docdb-sm-2' # name of CloudFormation stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1576c05",
   "metadata": {},
   "source": [
    "## The training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3807a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat src/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b2caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the certificate bundle for SM training jobs\n",
    "!cp rds-combined-ca-bundle.pem src/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb05566",
   "metadata": {},
   "source": [
    "## SageMaker's estimator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53644159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "# Get DocumentDB credentials stored in Secrets Manager\n",
    "def get_secret(stack_name):\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=session.region_name\n",
    "    )\n",
    "    \n",
    "    secret_name = f'{stack_name}-DocDBSecret'\n",
    "    get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5daba540",
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets = get_secret(stack_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59663b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "513908ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.client('ec2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2184ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find NAT subnet ID \n",
    "resp = ec2.describe_subnets(\n",
    "    Filters=[{'Name': 'tag:Name', 'Values': ['NAT_subnet']}]\n",
    ")\n",
    "nat_subnet_id = resp['Subnets'][0]['SubnetId']\n",
    "# print(nat_subnet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4045d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find security group ids\n",
    "resp = ec2.describe_security_groups(\n",
    "    Filters=[{\n",
    "        'Name': 'tag:Name', \n",
    "        'Values': ['{}-SG-DocumentDB'.format(stack_name)]\n",
    "    }])\n",
    "sg_id = resp['SecurityGroups'][0]['GroupId']\n",
    "# print(sg_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b12680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "CODE_PATH = \"main.py\"\n",
    "account = sess.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "params = {\n",
    "    'patience': 5, \n",
    "    'n-epochs': 20,\n",
    "    'batch-size': 64,\n",
    "    'db-host': secrets['host'],\n",
    "    'db-username': secrets['username'], \n",
    "    'db-password': secrets['password'], \n",
    "    'db-port': secrets['port'],\n",
    "    \n",
    "}\n",
    "task_tags = [{\"Key\": \"ML Task\", \"Value\": \"DGL\"}]\n",
    "estimator = PyTorch(\n",
    "    entry_point=CODE_PATH,\n",
    "    source_dir='src',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "#     instance_type=\"ml.p3.2xlarge\",\n",
    "    instance_type='ml.c4.2xlarge',\n",
    "    framework_version=\"1.7.1\",\n",
    "    py_version=\"py3\",\n",
    "    hyperparameters=params,\n",
    "    sagemaker_session=sess,\n",
    "    subnets=[nat_subnet_id], \n",
    "    security_group_ids=[sg_id],    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "026d8594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.get_vpc_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d12c45",
   "metadata": {},
   "source": [
    "## Running the Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73bdea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-03 20:38:54 Starting - Starting the training job...\n",
      "2021-09-03 20:38:57 Starting - Launching requested ML instancesProfilerReport-1630701533: InProgress\n",
      "......\n",
      "2021-09-03 20:40:15 Starting - Preparing the instances for training.........\n",
      "2021-09-03 20:41:40 Downloading - Downloading input data...\n",
      "2021-09-03 20:42:21 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-09-03 20:42:22,004 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-09-03 20:42:22,005 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-09-03 20:42:22,016 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-09-03 20:42:28,299 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-09-03 20:42:28,657 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting pymongo==3.12.0\n",
      "  Downloading pymongo-3.12.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (523 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pymongo\u001b[0m\n",
      "\u001b[34mSuccessfully installed pymongo-3.12.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\n",
      "\u001b[34m2021-09-03 20:42:31,291 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-09-03 20:42:31,303 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-09-03 20:42:31,317 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-09-03 20:42:31,328 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 64,\n",
      "        \"db-username\": \"username\",\n",
      "        \"db-host\": \"docdb-sm-2-documentdb.cluster-c7ij0vyhvynp.us-east-1.docdb.amazonaws.com\",\n",
      "        \"db-port\": 27017,\n",
      "        \"n-epochs\": 20,\n",
      "        \"patience\": 5,\n",
      "        \"db-password\": \"password1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2021-09-03-20-38-53-878\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-479389006481/pytorch-training-2021-09-03-20-38-53-878/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"main\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"main.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":64,\"db-host\":\"docdb-sm-2-documentdb.cluster-c7ij0vyhvynp.us-east-1.docdb.amazonaws.com\",\"db-password\":\"password1\",\"db-port\":27017,\"db-username\":\"username\",\"n-epochs\":20,\"patience\":5}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=main.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=main\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-479389006481/pytorch-training-2021-09-03-20-38-53-878/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"db-host\":\"docdb-sm-2-documentdb.cluster-c7ij0vyhvynp.us-east-1.docdb.amazonaws.com\",\"db-password\":\"password1\",\"db-port\":27017,\"db-username\":\"username\",\"n-epochs\":20,\"patience\":5},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-09-03-20-38-53-878\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-479389006481/pytorch-training-2021-09-03-20-38-53-878/source/sourcedir.tar.gz\",\"module_name\":\"main\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"main.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"64\",\"--db-host\",\"docdb-sm-2-documentdb.cluster-c7ij0vyhvynp.us-east-1.docdb.amazonaws.com\",\"--db-password\",\"password1\",\"--db-port\",\"27017\",\"--db-username\",\"username\",\"--n-epochs\",\"20\",\"--patience\",\"5\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_DB-USERNAME=username\u001b[0m\n",
      "\u001b[34mSM_HP_DB-HOST=docdb-sm-2-documentdb.cluster-c7ij0vyhvynp.us-east-1.docdb.amazonaws.com\u001b[0m\n",
      "\u001b[34mSM_HP_DB-PORT=27017\u001b[0m\n",
      "\u001b[34mSM_HP_N-EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_PATIENCE=5\u001b[0m\n",
      "\u001b[34mSM_HP_DB-PASSWORD=password1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 main.py --batch-size 64 --db-host docdb-sm-2-documentdb.cluster-c7ij0vyhvynp.us-east-1.docdb.amazonaws.com --db-password password1 --db-port 27017 --db-username username --n-epochs 20 --patience 5\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m{'batch_size': 64, 'lr': 0.001, 'n_epochs': 20, 'db_host': 'docdb-sm-2-documentdb.cluster-c7ij0vyhvynp.us-east-1.docdb.amazonaws.com', 'db_port': '27017', 'db_username': 'username', 'db_password': 'password1', 'patience': 5}\u001b[0m\n",
      "\u001b[34m[2021-09-03 20:42:35.236 algo-1:32 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-09-03 20:42:35.370 algo-1:32 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-09-03 20:42:35.371 algo-1:32 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-09-03 20:42:35.371 algo-1:32 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-09-03 20:42:35.371 algo-1:32 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-09-03 20:42:35.372 algo-1:32 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-09-03 20:42:37.793 algo-1:32 INFO hook.py:591] name:conv1.weight count_params:336\u001b[0m\n",
      "\u001b[34m[2021-09-03 20:42:37.793 algo-1:32 INFO hook.py:591] name:conv1.bias count_params:16\u001b[0m\n",
      "\u001b[34m[2021-09-03 20:42:37.793 algo-1:32 INFO hook.py:591] name:conv2.weight count_params:16\u001b[0m\n",
      "\u001b[34m[2021-09-03 20:42:37.794 algo-1:32 INFO hook.py:591] name:conv2.bias count_params:1\u001b[0m\n",
      "\u001b[34m[2021-09-03 20:42:37.794 algo-1:32 INFO hook.py:593] Total Trainable Params: 369\u001b[0m\n",
      "\u001b[34m[2021-09-03 20:42:37.794 algo-1:32 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-09-03 20:42:37.798 algo-1:32 INFO hook.py:488] Hook is writing from the hook with pid: 32\n",
      "\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 1, loss 0.6137\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 2, loss 0.6105\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 3, loss 0.6068\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 4, loss 0.6028\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 5, loss 0.6770\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 6, loss 0.7997\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 7, loss 0.8014\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 8, loss 0.7996\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 9, loss 0.5956\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 10, loss 0.5951\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 11, loss 0.5958\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 12, loss 0.5948\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 13, loss 0.7050\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 14, loss 0.8064\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 15, loss 0.8037\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 16, loss 0.8036\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 17, loss 0.5925\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 18, loss 0.5931\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 19, loss 0.5935\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 20, loss 0.5920\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 21, loss 0.7020\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 22, loss 0.8072\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 23, loss 0.8074\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 24, loss 0.8070\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 25, loss 0.5904\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 26, loss 0.5909\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 27, loss 0.5915\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 28, loss 0.5917\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 29, loss 0.7138\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 30, loss 0.8068\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 31, loss 0.8082\u001b[0m\n",
      "\u001b[34mepoch 1/20, batch 32, loss 0.8082\u001b[0m\n",
      "\u001b[34mepoch 1/20, training roc-auc 0.3600\u001b[0m\n",
      "\u001b[34mepoch 1/20, validation roc-auc 0.5401, best validation roc-auc 0.5401\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 1, loss 0.5905\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 2, loss 0.5903\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 3, loss 0.5910\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 4, loss 0.5902\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 5, loss 0.7093\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 6, loss 0.8096\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 7, loss 0.8101\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 8, loss 0.8069\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 9, loss 0.5896\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 10, loss 0.5896\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 11, loss 0.5902\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 12, loss 0.5894\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 13, loss 0.6984\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 14, loss 0.8097\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 15, loss 0.8092\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 16, loss 0.8090\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 17, loss 0.5875\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 18, loss 0.5894\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 19, loss 0.5896\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 20, loss 0.5894\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 21, loss 0.6783\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 22, loss 0.8107\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 23, loss 0.8072\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 24, loss 0.8089\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 25, loss 0.5885\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 26, loss 0.5887\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 27, loss 0.5889\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 28, loss 0.5875\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 29, loss 0.7103\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 30, loss 0.8085\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 31, loss 0.8107\u001b[0m\n",
      "\u001b[34mepoch 2/20, batch 32, loss 0.8105\u001b[0m\n",
      "\u001b[34mepoch 2/20, training roc-auc 0.4770\u001b[0m\n",
      "\u001b[34mepoch 2/20, validation roc-auc 0.5823, best validation roc-auc 0.5823\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 1, loss 0.5872\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 2, loss 0.5873\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 3, loss 0.5879\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 4, loss 0.5870\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 5, loss 0.6895\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 6, loss 0.8108\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 7, loss 0.8124\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 8, loss 0.8111\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 9, loss 0.5863\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 10, loss 0.5863\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 11, loss 0.5868\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 12, loss 0.5861\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 13, loss 0.7013\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 14, loss 0.8118\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 15, loss 0.8105\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 16, loss 0.8121\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 17, loss 0.5863\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 18, loss 0.5866\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 19, loss 0.5876\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 20, loss 0.5866\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 21, loss 0.7092\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 22, loss 0.8126\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 23, loss 0.8122\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 24, loss 0.8112\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 25, loss 0.5848\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 26, loss 0.5866\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 27, loss 0.5863\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 28, loss 0.5858\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 29, loss 0.6951\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 30, loss 0.8138\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 31, loss 0.8124\u001b[0m\n",
      "\u001b[34mepoch 3/20, batch 32, loss 0.8118\u001b[0m\n",
      "\u001b[34mepoch 3/20, training roc-auc 0.5140\u001b[0m\n",
      "\u001b[34mepoch 3/20, validation roc-auc 0.6215, best validation roc-auc 0.6215\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 1, loss 0.5845\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 2, loss 0.5852\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 3, loss 0.5858\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 4, loss 0.5856\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 5, loss 0.7070\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 6, loss 0.8103\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 7, loss 0.8137\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 8, loss 0.8118\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 9, loss 0.5848\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 10, loss 0.5850\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 11, loss 0.5848\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 12, loss 0.5845\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 13, loss 0.6885\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 14, loss 0.8145\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 15, loss 0.8147\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 16, loss 0.8134\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 17, loss 0.5840\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 18, loss 0.5832\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 19, loss 0.5849\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 20, loss 0.5834\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 21, loss 0.7057\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 22, loss 0.8155\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 23, loss 0.8139\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 24, loss 0.8141\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 25, loss 0.5823\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 26, loss 0.5850\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 27, loss 0.5847\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 28, loss 0.5831\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 29, loss 0.6930\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 30, loss 0.8159\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 31, loss 0.8122\u001b[0m\n",
      "\u001b[34mepoch 4/20, batch 32, loss 0.8148\u001b[0m\n",
      "\u001b[34mepoch 4/20, training roc-auc 0.5498\u001b[0m\n",
      "\u001b[34mepoch 4/20, validation roc-auc 0.6545, best validation roc-auc 0.6545\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 1, loss 0.5831\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 2, loss 0.5831\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 3, loss 0.5834\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 4, loss 0.5834\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 5, loss 0.7155\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 6, loss 0.8163\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 7, loss 0.8151\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 8, loss 0.8132\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 9, loss 0.5827\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 10, loss 0.5828\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 11, loss 0.5831\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 12, loss 0.5821\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 13, loss 0.6918\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 14, loss 0.8121\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 15, loss 0.8152\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 16, loss 0.8160\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 17, loss 0.5818\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 18, loss 0.5820\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 19, loss 0.5834\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 20, loss 0.5816\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 21, loss 0.6986\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 22, loss 0.8177\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 23, loss 0.8150\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 24, loss 0.8152\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 25, loss 0.5796\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 26, loss 0.5823\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 27, loss 0.5822\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 28, loss 0.5813\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 29, loss 0.6872\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 30, loss 0.8168\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 31, loss 0.8164\u001b[0m\n",
      "\u001b[34mepoch 5/20, batch 32, loss 0.8174\u001b[0m\n",
      "\u001b[34mepoch 5/20, training roc-auc 0.5800\u001b[0m\n",
      "\u001b[34mepoch 5/20, validation roc-auc 0.6834, best validation roc-auc 0.6834\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 1, loss 0.5797\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 2, loss 0.5806\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 3, loss 0.5818\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 4, loss 0.5813\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 5, loss 0.6950\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 6, loss 0.8177\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 7, loss 0.8163\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 8, loss 0.8152\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 9, loss 0.5797\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 10, loss 0.5807\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 11, loss 0.5806\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 12, loss 0.5797\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 13, loss 0.6949\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 14, loss 0.8182\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 15, loss 0.8186\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 16, loss 0.8171\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 17, loss 0.5804\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 18, loss 0.5801\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 19, loss 0.5799\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 20, loss 0.5796\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 21, loss 0.7096\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 22, loss 0.8152\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 23, loss 0.8191\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 24, loss 0.8185\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 25, loss 0.5781\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 26, loss 0.5797\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 27, loss 0.5807\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 28, loss 0.5783\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 29, loss 0.6936\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 30, loss 0.8204\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 31, loss 0.8162\u001b[0m\n",
      "\u001b[34mepoch 6/20, batch 32, loss 0.8205\u001b[0m\n",
      "\u001b[34mepoch 6/20, training roc-auc 0.6045\u001b[0m\n",
      "\u001b[34mepoch 6/20, validation roc-auc 0.7096, best validation roc-auc 0.7096\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 1, loss 0.5788\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 2, loss 0.5804\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 3, loss 0.5786\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 4, loss 0.5784\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 5, loss 0.6950\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 6, loss 0.8200\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 7, loss 0.8198\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 8, loss 0.8193\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 9, loss 0.5774\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 10, loss 0.5779\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 11, loss 0.5807\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 12, loss 0.5789\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 13, loss 0.7047\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 14, loss 0.8162\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 15, loss 0.8203\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 16, loss 0.8194\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 17, loss 0.5776\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 18, loss 0.5780\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 19, loss 0.5777\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 20, loss 0.5765\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 21, loss 0.7058\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 22, loss 0.8200\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 23, loss 0.8196\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 24, loss 0.8183\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 25, loss 0.5762\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 26, loss 0.5773\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 27, loss 0.5788\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 28, loss 0.5777\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 29, loss 0.6865\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 30, loss 0.8210\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 31, loss 0.8159\u001b[0m\n",
      "\u001b[34mepoch 7/20, batch 32, loss 0.8206\u001b[0m\n",
      "\u001b[34mepoch 7/20, training roc-auc 0.6306\u001b[0m\n",
      "\u001b[34mepoch 7/20, validation roc-auc 0.7301, best validation roc-auc 0.7301\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 1, loss 0.5755\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 2, loss 0.5770\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 3, loss 0.5773\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 4, loss 0.5759\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 5, loss 0.7169\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 6, loss 0.8212\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 7, loss 0.8218\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 8, loss 0.8199\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 9, loss 0.5771\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 10, loss 0.5766\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 11, loss 0.5775\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 12, loss 0.5779\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 13, loss 0.6938\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 14, loss 0.8217\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 15, loss 0.8205\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 16, loss 0.8204\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 17, loss 0.5767\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 18, loss 0.5776\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 19, loss 0.5771\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 20, loss 0.5760\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 21, loss 0.6818\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 22, loss 0.8211\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 23, loss 0.8175\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 24, loss 0.8205\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 25, loss 0.5744\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 26, loss 0.5765\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 27, loss 0.5781\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 28, loss 0.5754\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 29, loss 0.6995\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 30, loss 0.8173\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 31, loss 0.8205\u001b[0m\n",
      "\u001b[34mepoch 8/20, batch 32, loss 0.8219\u001b[0m\n",
      "\u001b[34mepoch 8/20, training roc-auc 0.6497\u001b[0m\n",
      "\u001b[34mepoch 8/20, validation roc-auc 0.7462, best validation roc-auc 0.7462\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 1, loss 0.5754\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 2, loss 0.5754\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 3, loss 0.5760\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 4, loss 0.5755\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 5, loss 0.6939\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 6, loss 0.8219\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 7, loss 0.8222\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 8, loss 0.8221\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 9, loss 0.5731\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 10, loss 0.5755\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 11, loss 0.5759\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 12, loss 0.5738\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 13, loss 0.6905\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 14, loss 0.8197\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 15, loss 0.8222\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 16, loss 0.8212\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 17, loss 0.5737\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 18, loss 0.5738\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 19, loss 0.5754\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 20, loss 0.5743\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 21, loss 0.6924\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 22, loss 0.8241\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 23, loss 0.8232\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 24, loss 0.8227\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 25, loss 0.5733\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 26, loss 0.5751\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 27, loss 0.5746\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 28, loss 0.5733\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 29, loss 0.7157\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 30, loss 0.8231\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 31, loss 0.8199\u001b[0m\n",
      "\u001b[34mepoch 9/20, batch 32, loss 0.8248\u001b[0m\n",
      "\u001b[34mepoch 9/20, training roc-auc 0.6637\u001b[0m\n",
      "\u001b[34mepoch 9/20, validation roc-auc 0.7606, best validation roc-auc 0.7606\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 1, loss 0.5728\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 2, loss 0.5747\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 3, loss 0.5751\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 4, loss 0.5746\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 5, loss 0.6860\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 6, loss 0.8244\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 7, loss 0.8223\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 8, loss 0.8225\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 9, loss 0.5727\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 10, loss 0.5738\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 11, loss 0.5732\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 12, loss 0.5712\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 13, loss 0.7137\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 14, loss 0.8238\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 15, loss 0.8221\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 16, loss 0.8235\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 17, loss 0.5713\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 18, loss 0.5732\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 19, loss 0.5738\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 20, loss 0.5719\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 21, loss 0.7088\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 22, loss 0.8194\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 23, loss 0.8244\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 24, loss 0.8243\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 25, loss 0.5724\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 26, loss 0.5719\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 27, loss 0.5740\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 28, loss 0.5732\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 29, loss 0.6808\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 30, loss 0.8250\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 31, loss 0.8225\u001b[0m\n",
      "\u001b[34mepoch 10/20, batch 32, loss 0.8248\u001b[0m\n",
      "\u001b[34mepoch 10/20, training roc-auc 0.6819\u001b[0m\n",
      "\u001b[34mepoch 10/20, validation roc-auc 0.7728, best validation roc-auc 0.7728\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 1, loss 0.5719\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 2, loss 0.5738\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 3, loss 0.5738\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 4, loss 0.5715\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 5, loss 0.7015\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 6, loss 0.8240\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 7, loss 0.8203\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 8, loss 0.8228\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 9, loss 0.5713\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 10, loss 0.5716\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 11, loss 0.5732\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 12, loss 0.5724\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 13, loss 0.7068\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 14, loss 0.8252\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 15, loss 0.8237\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 16, loss 0.8241\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 17, loss 0.5707\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 18, loss 0.5722\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 19, loss 0.5727\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 20, loss 0.5712\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 21, loss 0.6718\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 22, loss 0.8206\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 23, loss 0.8251\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 24, loss 0.8249\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 25, loss 0.5698\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 26, loss 0.5712\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 27, loss 0.5712\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 28, loss 0.5704\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 29, loss 0.7100\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 30, loss 0.8263\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 31, loss 0.8261\u001b[0m\n",
      "\u001b[34mepoch 11/20, batch 32, loss 0.8278\u001b[0m\n",
      "\u001b[34mepoch 11/20, training roc-auc 0.6905\u001b[0m\n",
      "\u001b[34mepoch 11/20, validation roc-auc 0.7834, best validation roc-auc 0.7834\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 1, loss 0.5686\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 2, loss 0.5706\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 3, loss 0.5714\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 4, loss 0.5710\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 5, loss 0.6911\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 6, loss 0.8263\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 7, loss 0.8208\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 8, loss 0.8247\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 9, loss 0.5699\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 10, loss 0.5703\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 11, loss 0.5718\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 12, loss 0.5693\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 13, loss 0.7203\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 14, loss 0.8265\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 15, loss 0.8256\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 16, loss 0.8269\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 17, loss 0.5690\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 18, loss 0.5725\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 19, loss 0.5705\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 20, loss 0.5693\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 21, loss 0.6771\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 22, loss 0.8273\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 23, loss 0.8272\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 24, loss 0.8262\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 25, loss 0.5701\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 26, loss 0.5693\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 27, loss 0.5715\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 28, loss 0.5698\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 29, loss 0.7000\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 30, loss 0.8194\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 31, loss 0.8257\u001b[0m\n",
      "\u001b[34mepoch 12/20, batch 32, loss 0.8260\u001b[0m\n",
      "\u001b[34mepoch 12/20, training roc-auc 0.7019\u001b[0m\n",
      "\u001b[34mepoch 12/20, validation roc-auc 0.7916, best validation roc-auc 0.7916\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 1, loss 0.5677\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 2, loss 0.5720\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 3, loss 0.5711\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 4, loss 0.5689\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 5, loss 0.6776\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 6, loss 0.8275\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 7, loss 0.8236\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 8, loss 0.8260\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 9, loss 0.5685\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 10, loss 0.5682\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 11, loss 0.5700\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 12, loss 0.5694\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 13, loss 0.6989\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 14, loss 0.8231\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 15, loss 0.8252\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 16, loss 0.8288\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 17, loss 0.5670\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 18, loss 0.5685\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 19, loss 0.5699\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 20, loss 0.5666\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 21, loss 0.7108\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 22, loss 0.8284\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 23, loss 0.8288\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 24, loss 0.8280\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 25, loss 0.5681\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 26, loss 0.5678\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 27, loss 0.5679\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 28, loss 0.5681\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 29, loss 0.7004\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 30, loss 0.8254\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 31, loss 0.8262\u001b[0m\n",
      "\u001b[34mepoch 13/20, batch 32, loss 0.8264\u001b[0m\n",
      "\u001b[34mepoch 13/20, training roc-auc 0.7094\u001b[0m\n",
      "\u001b[34mepoch 13/20, validation roc-auc 0.7982, best validation roc-auc 0.7982\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 1, loss 0.5661\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 2, loss 0.5695\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 3, loss 0.5701\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 4, loss 0.5681\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 5, loss 0.6903\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 6, loss 0.8219\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 7, loss 0.8281\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 8, loss 0.8285\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 9, loss 0.5668\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 10, loss 0.5691\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 11, loss 0.5677\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 12, loss 0.5663\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 13, loss 0.6930\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 14, loss 0.8283\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 15, loss 0.8237\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 16, loss 0.8288\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 17, loss 0.5673\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 18, loss 0.5677\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 19, loss 0.5683\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 20, loss 0.5679\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 21, loss 0.7062\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 22, loss 0.8293\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 23, loss 0.8269\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 24, loss 0.8284\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 25, loss 0.5659\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 26, loss 0.5654\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 27, loss 0.5684\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 28, loss 0.5656\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 29, loss 0.6966\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 30, loss 0.8276\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 31, loss 0.8276\u001b[0m\n",
      "\u001b[34mepoch 14/20, batch 32, loss 0.8266\u001b[0m\n",
      "\u001b[34mepoch 14/20, training roc-auc 0.7176\u001b[0m\n",
      "\u001b[34mepoch 14/20, validation roc-auc 0.8032, best validation roc-auc 0.8032\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 1, loss 0.5651\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 2, loss 0.5660\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 3, loss 0.5708\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 4, loss 0.5667\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 5, loss 0.7008\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 6, loss 0.8285\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 7, loss 0.8260\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 8, loss 0.8279\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 9, loss 0.5640\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 10, loss 0.5671\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 11, loss 0.5682\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 12, loss 0.5667\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 13, loss 0.7083\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 14, loss 0.8296\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 15, loss 0.8242\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 16, loss 0.8302\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 17, loss 0.5654\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 18, loss 0.5675\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 19, loss 0.5656\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 20, loss 0.5662\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 21, loss 0.6965\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 22, loss 0.8216\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 23, loss 0.8289\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 24, loss 0.8302\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 25, loss 0.5678\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 26, loss 0.5680\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 27, loss 0.5662\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 28, loss 0.5647\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 29, loss 0.6781\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 30, loss 0.8284\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 31, loss 0.8282\u001b[0m\n",
      "\u001b[34mepoch 15/20, batch 32, loss 0.8254\u001b[0m\n",
      "\u001b[34mepoch 15/20, training roc-auc 0.7241\u001b[0m\n",
      "\u001b[34mepoch 15/20, validation roc-auc 0.8079, best validation roc-auc 0.8079\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 1, loss 0.5673\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 2, loss 0.5670\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 3, loss 0.5663\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 4, loss 0.5668\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 5, loss 0.7040\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 6, loss 0.8291\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 7, loss 0.8287\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 8, loss 0.8299\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 9, loss 0.5645\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 10, loss 0.5656\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 11, loss 0.5673\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 12, loss 0.5636\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 13, loss 0.6790\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 14, loss 0.8280\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 15, loss 0.8275\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 16, loss 0.8288\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 17, loss 0.5619\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 18, loss 0.5656\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 19, loss 0.5673\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 20, loss 0.5655\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 21, loss 0.6926\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 22, loss 0.8250\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 23, loss 0.8250\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 24, loss 0.8292\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 25, loss 0.5631\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 26, loss 0.5654\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 27, loss 0.5652\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 28, loss 0.5628\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 29, loss 0.7089\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 30, loss 0.8292\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 31, loss 0.8296\u001b[0m\n",
      "\u001b[34mepoch 16/20, batch 32, loss 0.8303\u001b[0m\n",
      "\u001b[34mepoch 16/20, training roc-auc 0.7262\u001b[0m\n",
      "\u001b[34mepoch 16/20, validation roc-auc 0.8124, best validation roc-auc 0.8124\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 1, loss 0.5628\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 2, loss 0.5655\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 3, loss 0.5652\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 4, loss 0.5650\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 5, loss 0.6947\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 6, loss 0.8311\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 7, loss 0.8238\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 8, loss 0.8300\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 9, loss 0.5614\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 10, loss 0.5646\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 11, loss 0.5670\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 12, loss 0.5632\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 13, loss 0.7010\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 14, loss 0.8297\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 15, loss 0.8287\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 16, loss 0.8326\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 17, loss 0.5641\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 18, loss 0.5648\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 19, loss 0.5657\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 20, loss 0.5621\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 21, loss 0.6933\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 22, loss 0.8216\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 23, loss 0.8310\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 24, loss 0.8302\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 25, loss 0.5635\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 26, loss 0.5637\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 27, loss 0.5633\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 28, loss 0.5637\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 29, loss 0.6933\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 30, loss 0.8313\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 31, loss 0.8296\u001b[0m\n",
      "\u001b[34mepoch 17/20, batch 32, loss 0.8282\u001b[0m\n",
      "\u001b[34mepoch 17/20, training roc-auc 0.7325\u001b[0m\n",
      "\u001b[34mepoch 17/20, validation roc-auc 0.8150, best validation roc-auc 0.8150\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 1, loss 0.5612\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 2, loss 0.5620\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 3, loss 0.5623\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 4, loss 0.5626\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 5, loss 0.6999\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 6, loss 0.8310\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 7, loss 0.8254\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 8, loss 0.8299\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 9, loss 0.5630\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 10, loss 0.5655\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 11, loss 0.5664\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 12, loss 0.5614\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 13, loss 0.6983\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 14, loss 0.8231\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 15, loss 0.8292\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 16, loss 0.8281\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 17, loss 0.5625\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 18, loss 0.5643\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 19, loss 0.5632\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 20, loss 0.5630\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 21, loss 0.7087\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 22, loss 0.8318\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 23, loss 0.8307\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 24, loss 0.8316\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 25, loss 0.5609\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 26, loss 0.5632\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 27, loss 0.5661\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 28, loss 0.5631\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 29, loss 0.6726\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 30, loss 0.8289\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 31, loss 0.8291\u001b[0m\n",
      "\u001b[34mepoch 18/20, batch 32, loss 0.8340\u001b[0m\n",
      "\u001b[34mepoch 18/20, training roc-auc 0.7356\u001b[0m\n",
      "\u001b[34mepoch 18/20, validation roc-auc 0.8179, best validation roc-auc 0.8179\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 1, loss 0.5620\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 2, loss 0.5606\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 3, loss 0.5633\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 4, loss 0.5618\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 5, loss 0.6947\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 6, loss 0.8314\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 7, loss 0.8309\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 8, loss 0.8333\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 9, loss 0.5623\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 10, loss 0.5663\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 11, loss 0.5627\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 12, loss 0.5622\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 13, loss 0.6774\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 14, loss 0.8260\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 15, loss 0.8257\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 16, loss 0.8309\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 17, loss 0.5592\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 18, loss 0.5630\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 19, loss 0.5624\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 20, loss 0.5605\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 21, loss 0.6964\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 22, loss 0.8322\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 23, loss 0.8313\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 24, loss 0.8300\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 25, loss 0.5588\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 26, loss 0.5599\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 27, loss 0.5644\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 28, loss 0.5600\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 29, loss 0.7126\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 30, loss 0.8284\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 31, loss 0.8298\u001b[0m\n",
      "\u001b[34mepoch 19/20, batch 32, loss 0.8334\u001b[0m\n",
      "\u001b[34mepoch 19/20, training roc-auc 0.7368\u001b[0m\n",
      "\u001b[34mepoch 19/20, validation roc-auc 0.8198, best validation roc-auc 0.8198\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 1, loss 0.5592\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 2, loss 0.5627\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 3, loss 0.5624\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 4, loss 0.5603\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 5, loss 0.7163\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 6, loss 0.8332\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 7, loss 0.8295\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 8, loss 0.8329\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 9, loss 0.5608\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 10, loss 0.5609\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 11, loss 0.5624\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 12, loss 0.5604\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 13, loss 0.6908\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 14, loss 0.8241\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 15, loss 0.8298\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 16, loss 0.8335\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 17, loss 0.5600\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 18, loss 0.5622\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 19, loss 0.5629\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 20, loss 0.5597\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 21, loss 0.6850\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 22, loss 0.8298\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 23, loss 0.8300\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 24, loss 0.8313\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 25, loss 0.5589\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 26, loss 0.5613\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 27, loss 0.5623\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 28, loss 0.5613\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 29, loss 0.6856\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 30, loss 0.8307\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 31, loss 0.8280\u001b[0m\n",
      "\u001b[34mepoch 20/20, batch 32, loss 0.8296\u001b[0m\n",
      "\u001b[34mepoch 20/20, training roc-auc 0.7417\u001b[0m\n",
      "\u001b[34mepoch 20/20, validation roc-auc 0.8221, best validation roc-auc 0.8221\u001b[0m\n",
      "\u001b[34mBest validation score 0.8221\u001b[0m\n",
      "\u001b[34mTest score 0.7525\u001b[0m\n",
      "\u001b[34mUsing backend: pytorch\n",
      "\u001b[0m\n",
      "\u001b[34m2021-09-03 20:44:33,418 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-09-03 20:44:42 Uploading - Uploading generated training model\n",
      "2021-09-03 20:44:42 Completed - Training job completed\n",
      "Training seconds: 182\n",
      "Billable seconds: 182\n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373816ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
